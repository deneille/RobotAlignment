%YAML 1.1
%TAG !u! tag:unity3d.com,2011:
--- !u!114 &11400000
MonoBehaviour:
  m_ObjectHideFlags: 0
  m_CorrespondingSourceObject: {fileID: 0}
  m_PrefabInstance: {fileID: 0}
  m_PrefabAsset: {fileID: 0}
  m_GameObject: {fileID: 0}
  m_Enabled: 1
  m_EditorHideFlags: 0
  m_Script: {fileID: 11500000, guid: 702052c42a836454988958029d37c432, type: 3}
  m_Name: Enemy4_QuizData
  m_EditorClassIdentifier: 
  questions:
  - "The blue agent in DeepMind\u2019s experiment followed the red bot even when
    it led to penalties, showing goal misgeneralization."
  - An agent exploiting a reward loop is showing poor optimization skills.
  - AI safety is important because misaligned agents can behave unpredictably in
    high-stakes environments.
  answers: 010001
  timeLimit: 20
  correctAnswers:
  - Despite clear negative feedback (visible penalties), the blue agent still chose
    to follow the red bot, showing that it had internalized "follow the red bot"
    as its goal rather than the true reward structure.
  - An agent exploiting a reward loop is a show of strong optimization but goal misalignment.
  - AI Safety is important particularly as it relates to reinforcement learning,
    because of its use fields like healthcare (used in Dynamic Treatment Regimes),
    transportation (used in adapative traffic control) and more.
